{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "seminar_4.5_statistics.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fbeilstein/machine_learning/blob/master/seminar_5_naive_bayes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oD6O72hfJaYj",
        "colab_type": "text"
      },
      "source": [
        "#Estimating $P(C_k)$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jUgepi7XIr-T",
        "colab_type": "text"
      },
      "source": [
        "Suppose in a training set there are 15 documents labeled $C_1=\"Physics\"$, 25 documents labeled $C_2=\"Economics\"$ and $C_3=\"Religion\"$.\n",
        "\n",
        "Estimate $P(C_k)$ using MLE (emphirical frequencies)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nBQGCETyiIWy",
        "colab_type": "text"
      },
      "source": [
        "You are given list of documents $corpus$.\n",
        "You are also given a list of tags $tags$.\n",
        "\n",
        "Write function that calculates $C_k$."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QhfIJLQyi_jg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f624f587-def2-482e-ca22-ccff63767256"
      },
      "source": [
        "from collections import Counter\n",
        "def calculateCk(p):\n",
        "  counter = Counter(p)\n",
        "  out=[]\n",
        "  for i in counter:\n",
        "    out.append(counter[i]/len(p))\n",
        "  return out\n",
        "\n",
        "calculateCk([\"Physics\", \"Lyrics\", \"Lyrics\", \"Lyrics\"])"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.25, 0.75]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9z9XtqJziszO",
        "colab_type": "text"
      },
      "source": [
        "#Custom Count Vectorizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zHC8s5RuivSY",
        "colab_type": "text"
      },
      "source": [
        "Write your own simple Vectorizer that takes a vector $corpus$ of strings, prepares vocabulary $V$ and returns a table $|corpus|\\times|V|$ with counts of words of the vocabulary in each document. \n",
        "Your class would be analog of ```sklearn.feature_extraction.text.CountVectorizer```.\n",
        "The interface of our class should be as follows:\n",
        "* ```fit_transform(self, corpus)``` - feeds vectorizer a list of strings.\n",
        "* ```get_feature_names(self)``` - returns of lexigraphically sorted lowercase words in the vocabulary.\n",
        "* ```toarray(self)``` - returns array $|corpus|\\times|V|$ with counts.\n",
        "\n",
        "Note: you should get rid of punctuation marks and convert your lines into lowercase in all your documents.\n",
        "\n",
        "Now modify your code so that the counts are boolean ($1$ if the word is present in the document and $0$ otherwise).\n",
        "This corresponds to ```CountVectorizer(binary = True)```.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5w7zx6c56TGd",
        "colab_type": "text"
      },
      "source": [
        "##Standard Count Vectorizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sv8taV1Ejqku",
        "colab_type": "code",
        "outputId": "e1cd28a0-661a-4223-8f15-70cfa707dc97",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "corpus = ['This is the first document.', 'This document is the second document.',\n",
        "'And this is the third one.', 'Is this the first document?']\n",
        "\n",
        "vectorizer_C = CountVectorizer()\n",
        "C = vectorizer_C.fit_transform(corpus)\n",
        "print(\"Vocabulary : \", vectorizer_C.get_feature_names())\n",
        "print(\"arr :\", C.toarray())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Vocabulary :  ['and', 'document', 'first', 'is', 'one', 'second', 'the', 'third', 'this']\n",
            "arr : [[0 1 1 1 0 0 1 0 1]\n",
            " [0 1 0 1 0 1 1 0 1]\n",
            " [1 0 0 1 1 0 1 1 1]\n",
            " [0 1 1 1 0 0 1 0 1]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nI1XIj3Wzz8B",
        "colab_type": "text"
      },
      "source": [
        "##Solution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p4o_DKn_kUHE",
        "colab_type": "code",
        "outputId": "af43f3e7-9b6a-472b-c4db-c7fd38a264f2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "from collections import Counter\n",
        "import string\n",
        "\n",
        "class SimpleCountVectorizer:\n",
        "  \"\"\"Vectorizer that counts number of word occurrences in documents\"\"\"\n",
        "  def __init__(self, binary=False):\n",
        "    self.binary = binary\n",
        "    \n",
        "  def fit_transform(self, corpus):\n",
        "    self.vocabulary = set()\n",
        "    counters = []\n",
        "    self.counts = []\n",
        "    \n",
        "    for d in corpus:\n",
        "      counter = Counter()\n",
        "      table = str.maketrans({key: None for key in string.punctuation})\n",
        "      d_without_punct = d.translate(table) # deletes all punctuation\n",
        "      words = d_without_punct.lower().split()\n",
        "      self.vocabulary.update(set(words))\n",
        "      counter |= Counter(words)\n",
        "      counters.append(counter)\n",
        "    self.vocabulary = sorted(self.vocabulary)  \n",
        "    \n",
        "    for d_index in range(0, len(corpus)):\n",
        "      counts = []\n",
        "      for word in self.vocabulary:\n",
        "        count = int(counters[d_index][word] > 0) if self.binary else counters[d_index][word]\n",
        "        counts.append(count)\n",
        "      self.counts.append(counts)\n",
        " \n",
        "  def get_feature_names(self):\n",
        "    return self.vocabulary\n",
        "  \n",
        "  def toarray(self):\n",
        "    return  self.counts\n",
        "      \n",
        "  \n",
        "corpus = ['This is the first document.', 'This document is the second document.',\n",
        "'And this is the third one.', 'Is this the first document?']\n",
        "SCV = SimpleCountVectorizer(binary=True)\n",
        "SCV.fit_transform(corpus)\n",
        "print(\"Vocabulary : \", SCV.get_feature_names())\n",
        "print(\"arr :\", SCV.toarray())\n",
        "\n",
        "    "
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Vocabulary :  ['and', 'document', 'first', 'is', 'one', 'second', 'the', 'third', 'this']\n",
            "arr : [[0, 1, 1, 1, 0, 0, 1, 0, 1], [0, 1, 0, 1, 0, 1, 1, 0, 1], [1, 0, 0, 1, 1, 0, 1, 1, 1], [0, 1, 1, 1, 0, 0, 1, 0, 1]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D2b-Zv350DTN",
        "colab_type": "text"
      },
      "source": [
        "#Multinomial model parameters estimation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_RToFZMcynz4",
        "colab_type": "text"
      },
      "source": [
        "Suppose your dictionary contains words $\\{\"position\", \"velocity\", \"stocks\"\\}$.\n",
        "Suppose you have $3$ documents labeled as $\"Physics\"$.\n",
        "\n",
        "Your 1st document contains \n",
        "\n",
        "* word \"position\" $x_1=0$ times\n",
        "* word \"velocity\" $x_2=1$ times\n",
        "* word \"stocks\" $x_3=0$ times.\n",
        "\n",
        "Your 2nd document contains \n",
        "\n",
        "* word \"position\" $x_1=0$ times\n",
        "* word \"velocity\" $x_2=1$ times\n",
        "* word \"stocks\" $x_3=0$ times.\n",
        "\n",
        "Your 3rd document contains \n",
        "\n",
        "* word \"position\" $x_1=3$ times\n",
        "* word \"velocity\" $x_2=0$ times\n",
        "* word \"stocks\" $x_3=0$ times.\n",
        "\n",
        "Suppose you adopt multinomial model for word occurence\n",
        "\n",
        "$$\n",
        "P(\\{x_1,x_2,x_3\\}|\"Phycics\")=\\frac{(x_1+x_2+x_3)!}{x_1!x_2!x_3!} p_{1}^{x_1}p_{2}^{x_2}p_{3}^{x_3}\n",
        "$$\n",
        "\n",
        "With given data use emphirical frequency (with smoothing $\\alpha=0.1$) to estimate model parameters $p_1,p_2,p_3$ and verify that $p_1+p_2+p_3=1$.\n",
        "\n",
        "Note: You can aggregate counts in our three documents to get \n",
        "\n",
        "* word \"position\" $x_1=3$ times\n",
        "* word \"velocity\" $x_2=2$ times\n",
        "* word \"stocks\" $x_3=0$ times.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z0QmC1-e2vfg",
        "colab_type": "text"
      },
      "source": [
        "##Solution:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c30hNdDFz8Vm",
        "colab_type": "text"
      },
      "source": [
        "We have $K=3$ features ($3$ words in the vocabulary) and $n=3+2+0=5$ \"trials\" when we pick words from the \"bag\" with replacement.\n",
        "\n",
        "\n",
        "$$\n",
        "p_i=\\frac{n_i+ \\alpha}{N+K \\alpha}.\n",
        "$$\n",
        "\n",
        "So\n",
        "\n",
        "$$\n",
        "\\begin{aligned}\n",
        "p_1&=\\frac{n_1+ \\alpha}{n+K \\alpha}=\\frac{3+ 0.1}{5+3 \\times 0.1}=0.58, \\\\\n",
        "p_2&=\\frac{n_2+ \\alpha}{n+K \\alpha}=\\frac{2+ 0.1}{5+3 \\times 0.1}=0.4, \\\\\n",
        "p_3&=\\frac{n_3+ \\alpha}{n+K \\alpha}=\\frac{0+ 0.1}{5+3 \\times 0.1}=0.02.\n",
        "\\end{aligned}\n",
        "$$\n",
        "\n",
        "We see that\n",
        "\n",
        "$$\n",
        "p_1+p_2+p_3=0.58+0.4+0.02=1.\n",
        "$$\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kSuCoZfNIXBw",
        "colab_type": "text"
      },
      "source": [
        "#Multivariate Bernoulli model parameters estimation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jp6UKd7w38PH",
        "colab_type": "text"
      },
      "source": [
        "In the previos setup adopt multivariate Bernoulli model. \n",
        "Now we need to count not total number of occurencies in all documents but rather number of documents in which the word occurs.\n",
        "\n",
        "Your 1st document contains\n",
        "\n",
        "* word \"position\" is absent (bool frequency is $0$)\n",
        "* word \"velocity\" is present (bool frequency is $1$)\n",
        "* word \"stocks\" is absent (bool frequency is $0$)\n",
        "\n",
        "Your 2nd document contains\n",
        "\n",
        "* word \"position\" is absent (bool frequency is $0$)\n",
        "* word \"velocity\" is present (bool frequency is $1$)\n",
        "* word \"stocks\" is absent (bool frequency is $0$)\n",
        "\n",
        "Your 3rd document contains\n",
        "\n",
        "* word \"position\" is present (bool frequency is $1$)\n",
        "* word \"velocity\" is absent (bool frequency is $0$)\n",
        "* word \"stocks\" is absent (bool frequency is $0$)\n",
        "\n",
        "We can add boolean frequencies\n",
        "* word \"position\" is present in $1$ documents\n",
        "* word \"velocity\" is present in $2$ documents\n",
        "* word \"stocks\" $x_3=0$ times.\n",
        "\n",
        "The model \n",
        "\n",
        "$$\n",
        "P(\\{x_1,x_2,x_3\\})= p_{1}^{x_1}(1-p_1)^{1-x_1} \\times p_{2}^{x_2}(1-p_2)^{1-x_2} \\times p_{3}^{x_3}(1-p_3)^{1-x_3}\n",
        "$$\n",
        "\n",
        "where $x_i$ is either $0$ or $1$ (i.e. the word is either present in the document or not).\n",
        "\n",
        "With given data use emphirical frequency (with smoothing $\\alpha=0.1$) to estimate model parameters $p_1,p_2,p_3$ and verify that $p_1+p_2+p_3=1$.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "98bLnOnwMr9X",
        "colab_type": "text"
      },
      "source": [
        "##Solution"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u_jzP0KJMqQm",
        "colab_type": "text"
      },
      "source": [
        "$K=3$ (three words in the dictionary) and $n=1+2+0=3$. Therefore\n",
        "$$\n",
        "\\begin{aligned}\n",
        "p_1&=\\frac{n_1+ \\alpha}{n+K \\alpha}=\\frac{1+ 0.1}{3+3 \\times 0.1}=0.33, \\\\\n",
        "p_2&=\\frac{n_2+ \\alpha}{n+K \\alpha}=\\frac{2+ 0.1}{3+3 \\times 0.1}=0.64, \\\\\n",
        "p_3&=\\frac{n_3+ \\alpha}{n+K \\alpha}=\\frac{0+ 0.1}{3+3 \\times 0.1}=0.03.\n",
        "\\end{aligned}\n",
        "$$\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fOp6EfyFJphl",
        "colab_type": "text"
      },
      "source": [
        "#Automatic parameters estimation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6WkxuWa7JuZD",
        "colab_type": "text"
      },
      "source": [
        "Write class that performs multinomial and multivariate parameters estimation. The class gets array with counts from Vectorizer and returns vector with $p_i$s. You can also set $\\alpha$ in the constructor (default value is $1$). Verify your code with the example above."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ebBw1UgofzlR",
        "colab_type": "text"
      },
      "source": [
        "##Solution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CDElGnbOaCx1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MultinomialParametersEstimator:\n",
        "  \"\"\"Calculates parameters for Multinomial/multivariate Bernoulli model\"\"\"\n",
        "  def __init__(self, alpha=1):\n",
        "    self.alpha = alpha\n",
        "    \n",
        "  def get_params(self, counts):\n",
        "    sum = counts[0]\n",
        "    K = len(sum)\n",
        "    for i in range(1,len(counts)):\n",
        "      for j in range(0,K):\n",
        "        sum[j] += counts[i][j]\n",
        "    \n",
        "    n = 0\n",
        "    for i in range(0,K):\n",
        "      n += sum[i]\n",
        "      \n",
        "    for i in range(0,K):\n",
        "      sum[i] = (sum[i] + self.alpha) / (n + K * self.alpha)\n",
        "    return sum\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u_2vTI-kc_QR",
        "colab_type": "text"
      },
      "source": [
        "In the example **Multinomial model parameters estimation** we had\n",
        "$$counts=[[0,1,0],[0,1,0],[3,0,0]]$$\n",
        "\n",
        "and\n",
        "$$\n",
        "\\begin{aligned}\n",
        "p_1&=0.58, \\\\\n",
        "p_2&=0.4, \\\\\n",
        "p_3&=0.02.\n",
        "\\end{aligned}\n",
        "$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qO1iam_mdLTV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3f3c891a-6c1d-4171-d87f-7f2a77287dba"
      },
      "source": [
        "counts = [[0,1,0],[0,1,0],[3,0,0]]\n",
        "m = MultinomialParametersEstimator(0.1)\n",
        "m.get_params(counts)"
      ],
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.5849056603773585, 0.39622641509433965, 0.01886792452830189]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pgjYnmAVdXOW",
        "colab_type": "text"
      },
      "source": [
        "In the example **Multivariate Bernoulli model parameters estimation**\n",
        "$$bool counts=[[0,1,0],[0,1,0],[1,0,0]]$$\n",
        "\n",
        "and\n",
        "$$\n",
        "\\begin{aligned}\n",
        "p_1&=0.33, \\\\\n",
        "p_2&=0.64, \\\\\n",
        "p_3&=0.03.\n",
        "\\end{aligned}\n",
        "$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5YpD00X3eHDv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4c8cef28-b4e9-4e43-8908-1580e67ec8d5"
      },
      "source": [
        "counts = [[0,1,0],[0,1,0],[1,0,0]]\n",
        "m = MultinomialParametersEstimator(0.1)\n",
        "m.get_params(counts)"
      ],
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.33333333333333337, 0.6363636363636365, 0.030303030303030307]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uZkN4wgDgEUt",
        "colab_type": "text"
      },
      "source": [
        "#Calculating probabilities in multinomial model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bRQ5iYJzh2B-",
        "colab_type": "text"
      },
      "source": [
        "$$\n",
        "P(\\{x_1,x_2,x_3\\})=\\frac{(x_1+x_2+x_3)!}{x_1!x_2!x_3!} p_{1}^{x_1}p_{2}^{x_2}p_{3}^{x_3}\n",
        "$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fk6WaKObgKU5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f50d7e9d-2109-42fd-a59c-b6fc3300f71a"
      },
      "source": [
        "import math \n",
        "\n",
        "def multinomialP(x,p):\n",
        "  sum = 0\n",
        "    \n",
        "  for i in range (0, len(x)):\n",
        "    sum += x[i]\n",
        "    \n",
        "  P = math.gamma(sum+1)\n",
        "  \n",
        "  for i in range (0, len(x)):\n",
        "    P *= (p[i])**(x[i])/math.gamma(x[i] + 1)\n",
        "    \n",
        "  return P\n",
        "\n",
        "def posteriorMultinomialP(x, p, prior):\n",
        "  sum = 0\n",
        "    \n",
        "  for i in range (0, len(x)):\n",
        "    sum += x[i]\n",
        "    \n",
        "  P = math.gamma(sum+1)\n",
        "  \n",
        "  for i in range (0, len(x)):\n",
        "    P *= (p[i])**(x[i])/math.gamma(x[i] + 1)\n",
        "    \n",
        "  return P*prior\n",
        "\n",
        "\n",
        "multinomialP([2,4,5],[0.33,0.64,0.03])"
      ],
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3.076715106533376e-06"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 112
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k1aSs6BinUjH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b7e99932-8eb5-484f-929e-0a5ef7a4c8b6"
      },
      "source": [
        "  def countsOfWords(vocabulary, document):\n",
        "    counts = []\n",
        "    table = str.maketrans({key: None for key in string.punctuation})\n",
        "    d_without_punct = document.translate(table) # deletes all punctuation\n",
        "    words = d_without_punct.lower().split()\n",
        "    for i in vocabulary:\n",
        "      counts.append(words.count(i))\n",
        "    return counts\n",
        "  \n",
        "  countsOfWords([\"s\",\"d\"],\"s s d hjhkj\")"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2, 1]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8hpEfP40JhLR",
        "colab_type": "text"
      },
      "source": [
        "#Text classification with our own corpus"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZuDuxDjkJbPA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "categories=[\"Physics\", \"Economy\", \"Religion\"]\n",
        "\n",
        "P=[\"In Newtonian mechanics, linear momentum, translational momentum, or simply momentum (pl. momenta) is the product of the mass and velocity of an object.\",\n",
        "   \"A neutrino (denoted by the Greek letter ν) is a fermion (an elementary particle with half-integer spin) that interacts only via the weak subatomic force and gravity.\",\n",
        "   \"In physics, the center of mass of a distribution of mass in space is the unique point where the weighted relative position of the distributed mass sums to zero. This is the point to which a force may be applied to cause a linear acceleration without an angular acceleration.\"]\n",
        "\n",
        "E=[\"Money is any item or verifiable record that is generally accepted as payment for goods and services and repayment of debts, such as taxes, in a particular country or socio-economic context.\",\n",
        "   \"Originally money was a form of receipt, representing grain stored in temple granaries in Sumer in ancient Mesopotamia and later in Ancient Egypt. In this first stage of currency, metals were used as symbols to represent value stored in the form of commodities. \",\n",
        "   \"In economics, inflation is a increase in the general price level of goods and services in an economy over a period of time. When the general price level rises, each unit of currency buys fewer goods and services; consequently, inflation reflects a reduction in the purchasing power per unit of money – a loss of real value in the medium of exchange and unit of account within the economy.\"]\n",
        "\n",
        "R=[\"Christianity is an Abrahamic monotheistic religion based on the life and teachings of Jesus of Nazareth. Its adherents, known as Christians, believe that Jesus is the Christ, the Son of God, and the savior of all people, whose coming as the Messiah was prophesied in the Hebrew Bible, called the Old Testament in Christianity, and chronicled in the New Testament.\",\n",
        "   \"Traditionalist Catholicism is a set of religious beliefs made up of the customs, traditions, liturgical forms, public, private and group devotions, and presentations of the teaching of the Catholic Church before the Second Vatican Council\",\n",
        "   \"Most modern scholars believe that John the Baptist performed a baptism on Jesus, and view it as a historical event to which a high degree of certainty can be assigned.\"]\n",
        "\n",
        "tags = [0,0,0,1,1,1,2,2,2]\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.pipeline import make_pipeline\n",
        "\n",
        "#model = make_pipeline(TfidfVectorizer(), MultinomialNB())\n",
        "#model.fit(training_set.data, training_set.target)\n",
        "\n",
        "vectorizer = TfidfVectorizer()\n",
        "\n",
        "vectorizer.fit_transform(P)\n",
        "print(vectorizer.get_feature_names())\n",
        "vectorizer.fit_transform(E)\n",
        "print(vectorizer.get_feature_names())\n",
        "vectorizer.fit_transform(R)\n",
        "print(vectorizer.get_feature_names())\n",
        "\n",
        "\n",
        "training_set={'data':P+E+R,'target':tags}\n",
        "model.fit(training_set['data'], training_set['target']);\n",
        "labels = model.predict([\"Economy is physics\"])\n",
        "print(categories[labels[0]])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l8NIG--8lVju",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "fc9daefe-d856-4c40-d4cc-6ee70e7521f7"
      },
      "source": [
        "categories=[\"Physics\", \"Economy\", \"Religion\"]\n",
        "\n",
        "P=[\"In Newtonian mechanics, linear momentum, translational momentum, or simply momentum (pl. momenta) is the product of the mass and velocity of an object.\",\n",
        "   \"A neutrino (denoted by the Greek letter ν) is a fermion (an elementary particle with half-integer spin) that interacts only via the weak subatomic force and gravity.\",\n",
        "   \"In physics, the center of mass of a distribution of mass in space is the unique point where the weighted relative position of the distributed mass sums to zero. This is the point to which a force may be applied to cause a linear acceleration without an angular acceleration.\"]\n",
        "\n",
        "E=[\"Money is any item or verifiable record that is generally accepted as payment for goods and services and repayment of debts, such as taxes, in a particular country or socio-economic context.\",\n",
        "   \"Originally money was a form of receipt, representing grain stored in temple granaries in Sumer in ancient Mesopotamia and later in Ancient Egypt. In this first stage of currency, metals were used as symbols to represent value stored in the form of commodities. \",\n",
        "   \"In economics, inflation is a increase in the general price level of goods and services in an economy over a period of time. When the general price level rises, each unit of currency buys fewer goods and services; consequently, inflation reflects a reduction in the purchasing power per unit of money – a loss of real value in the medium of exchange and unit of account within the economy.\"]\n",
        "\n",
        "R=[\"Christianity is an Abrahamic monotheistic religion based on the life and teachings of Jesus of Nazareth. Its adherents, known as Christians, believe that Jesus is the Christ, the Son of God, and the savior of all people, whose coming as the Messiah was prophesied in the Hebrew Bible, called the Old Testament in Christianity, and chronicled in the New Testament.\",\n",
        "   \"Traditionalist Catholicism is a set of religious beliefs made up of the customs, traditions, liturgical forms, public, private and group devotions, and presentations of the teaching of the Catholic Church before the Second Vatican Council\",\n",
        "   \"Most modern scholars believe that John the Baptist performed a baptism on Jesus, and view it as a historical event to which a high degree of certainty can be assigned.\"]\n",
        "\n",
        "tags = [0,0,0,1,1,1,2,2,2]\n",
        "corpus = P+E+R\n",
        "\n",
        "d=\"Economy is physics\"\n",
        "\n",
        "Ck = calculateCk(tags)\n",
        "SCV = SimpleCountVectorizer(binary=False)\n",
        "SCV.fit_transform(corpus)\n",
        "arr = SCV.toarray()\n",
        "\n",
        "countsInDocument = countsOfWords(SCV.get_feature_names(), d)\n",
        "m = MultinomialParametersEstimator(0.1)\n",
        "p = m.get_params(arr)\n",
        "print(\"p=\" , p)\n",
        "#print(\"Vocabulary : \", SCV.get_feature_names())\n",
        "#print(\"arr :\", SCV.toarray())\n",
        "#print(\"Word count: \",countsOfWords(SCV.get_feature_names(), d))\n",
        "\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "p= [0.038947639927779214, 0.002837245292752128, 0.0054165591952540625, 0.002837245292752128, 0.002837245292752128, 0.002837245292752128, 0.002837245292752128, 0.013154500902759865, 0.0054165591952540625, 0.03636832602527728, 0.002837245292752128, 0.002837245292752128, 0.002837245292752128, 0.0157338148052618, 0.002837245292752128, 0.002837245292752128, 0.002837245292752128, 0.002837245292752128, 0.0054165591952540625, 0.002837245292752128, 0.002837245292752128, 0.0054165591952540625, 0.002837245292752128, 0.002837245292752128, 0.002837245292752128, 0.002837245292752128, 0.002837245292752128, 0.002837245292752128, 0.002837245292752128, 0.002837245292752128, 0.002837245292752128, 0.002837245292752128, 0.002837245292752128, 0.0054165591952540625, 0.002837245292752128, 0.002837245292752128, 0.002837245292752128, 0.002837245292752128, 0.002837245292752128, 0.002837245292752128, 0.002837245292752128, 0.002837245292752128, 0.002837245292752128, 0.0054165591952540625, 0.002837245292752128, 0.002837245292752128, 0.002837245292752128, 0.002837245292752128, 0.002837245292752128, 0.002837245292752128, 0.002837245292752128, 0.002837245292752128, 0.002837245292752128, 0.0054165591952540625, 0.002837245292752128, 0.002837245292752128, 0.002837245292752128, 0.002837245292752128, 0.002837245292752128, 0.002837245292752128, 0.002837245292752128, 0.002837245292752128, 0.0054165591952540625, 0.0054165591952540625, 0.002837245292752128, 0.0054165591952540625, 0.002837245292752128, 0.002837245292752128, 0.007995873097755997, 0.002837245292752128, 0.002837245292752128, 0.002837245292752128, 0.002837245292752128, 0.002837245292752128, 0.002837245292752128, 0.002837245292752128, 0.002837245292752128, 0.002837245292752128, 0.046685581635285016, 0.002837245292752128, 0.0054165591952540625, 0.002837245292752128, 0.026051070415269537, 0.002837245292752128, 0.002837245292752128, 0.002837245292752128, 0.007995873097755997, 0.002837245292752128, 0.002837245292752128, 0.002837245292752128, 0.002837245292752128, 0.0054165591952540625, 0.002837245292752128, 0.0054165591952540625, 0.002837245292752128, 0.002837245292752128, 0.002837245292752128, 0.01057518700025793, 0.002837245292752128, 0.002837245292752128, 0.002837245292752128, 0.002837245292752128, 0.002837245292752128, 0.002837245292752128, 0.002837245292752128, 0.002837245292752128, 0.007995873097755997, 0.007995873097755997, 0.002837245292752128, 0.002837245292752128, 0.002837245292752128, 0.002837245292752128, 0.002837245292752128, 0.002837245292752128, 0.002837245292752128, 0.0673200928553005, 0.002837245292752128, 0.0054165591952540625, 0.002837245292752128, 0.007995873097755997, 0.002837245292752128, 0.002837245292752128, 0.002837245292752128, 0.002837245292752128, 0.002837245292752128, 0.002837245292752128, 0.002837245292752128, 0.002837245292752128, 0.002837245292752128, 0.002837245292752128, 0.002837245292752128, 0.0054165591952540625, 0.002837245292752128, 0.002837245292752128, 0.002837245292752128, 0.0054165591952540625, 0.002837245292752128, 0.002837245292752128, 0.002837245292752128, 0.002837245292752128, 0.002837245292752128, 0.002837245292752128, 0.002837245292752128, 0.002837245292752128, 0.002837245292752128, 0.002837245292752128, 0.002837245292752128, 0.002837245292752128, 0.002837245292752128, 0.002837245292752128, 0.002837245292752128, 0.002837245292752128, 0.002837245292752128, 0.002837245292752128, 0.002837245292752128, 0.002837245292752128, 0.007995873097755997, 0.002837245292752128, 0.002837245292752128, 0.002837245292752128, 0.002837245292752128, 0.002837245292752128, 0.002837245292752128, 0.002837245292752128, 0.0054165591952540625, 0.002837245292752128, 0.002837245292752128, 0.002837245292752128, 0.002837245292752128, 0.002837245292752128, 0.002837245292752128, 0.002837245292752128, 0.002837245292752128, 0.002837245292752128, 0.0054165591952540625, 0.01057518700025793, 0.07247872066030436, 0.0054165591952540625, 0.002837245292752128, 0.013154500902759865, 0.002837245292752128, 0.002837245292752128, 0.002837245292752128, 0.002837245292752128, 0.007995873097755997, 0.002837245292752128, 0.002837245292752128, 0.0054165591952540625, 0.002837245292752128, 0.002837245292752128, 0.002837245292752128, 0.002837245292752128, 0.002837245292752128, 0.0054165591952540625, 0.002837245292752128, 0.002837245292752128, 0.002837245292752128, 0.002837245292752128, 0.002837245292752128, 0.0054165591952540625, 0.002837245292752128, 0.002837245292752128, 0.002837245292752128, 0.002837245292752128, 0.002837245292752128, 0.002837245292752128, 0.002837245292752128]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CPvQvIz9lRBW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}